{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"script","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.checkpoint as cp\nfrom collections import OrderedDict\n\nclass _Layer1(nn.Module):\n    def __init__(self, num_input_features):\n        super(_Layer1, self).__init__()\n        self.add_module('norm1', nn.BatchNorm2d(num_input_features)),\n        self.add_module('relu1', nn.ReLU(inplace=True)),\n        self.add_module('conv1', nn.Conv2d(num_input_features, num_input_features//2,\n                        kernel_size=3, stride=1, padding=1, bias=False)),\n    def forward(self, x):\n        out = self.conv1(self.relu1(self.norm1(x)))\n        return out\n\nclass _Layer2(nn.Module):\n    def __init__(self, num_input_features):\n        super(_Layer2, self).__init__()\n        self.add_module('norm1', nn.BatchNorm2d(num_input_features)),\n        self.add_module('relu1', nn.ReLU(inplace=True)),\n        self.add_module('conv1', nn.Conv2d(num_input_features, num_input_features,\n                        kernel_size=3, stride=1, padding=1, bias=False)),\n    def forward(self, x):\n        out = self.conv1(self.relu1(self.norm1(x)))\n        return out\n\nclass _Transition_Down(nn.Sequential):\n    def __init__(self, num_input_features, num_output_features):\n        super(_Transition_Down, self).__init__()\n        self.conv = nn.Conv2d(num_input_features, num_output_features, kernel_size=1, stride=1, bias=False)\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n    def forward(self, x):\n        out = self.conv(self.pool(x))\n        return out\n\nclass _Transition_Up(nn.Sequential):\n    def __init__(self, num_input_features, num_output_features):\n        super(_Transition_Up, self).__init__()\n        self.up_conv = nn.ConvTranspose2d(num_input_features, num_output_features,\n                                          kernel_size=2, stride=2, bias=False)\n    def forward(self, x):\n        out = self.up_conv(x)\n        return out\n\nclass _DenseBlock(nn.Module):\n    def __init__(self, num_layers, in_planes, growth_rate):\n        super(_DenseBlock, self).__init__()\n        self.layer = self._make_layer(in_planes, growth_rate, num_layers)\n    def _make_layer(self, in_planes, growth_rate, num_layers):\n        layers = []\n        for i in range(num_layers):\n            layers.append(_BottleneckLayer(in_planes+i*growth_rate, growth_rate))\n        return nn.Sequential(*layers)\n    def forward(self, x):\n        return self.layer(x)\n    \nclass _BottleneckLayer(nn.Module):\n    def __init__(self, in_planes, out_planes):\n        super(_BottleneckLayer, self).__init__()\n        inter_planes = out_planes * 4\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv1 = nn.Conv2d(in_planes, inter_planes, kernel_size=1, stride=1,\n                               padding=0, bias=False)\n        self.bn2 = nn.BatchNorm2d(inter_planes)\n        self.conv2 = nn.Conv2d(inter_planes, out_planes, kernel_size=3, stride=1,\n                               padding=1, bias=False)\n    def forward(self, x):\n        out = self.conv1(self.relu(self.bn1(x)))\n        out = self.conv2(self.relu(self.bn2(out)))\n        return torch.cat([x, out], 1)\n\nclass _DenseLayer(nn.Module):\n    def __init__(self, in_planes, out_planes):\n        super(_DenseLayer, self).__init__()\n        self.bn1 = nn.BatchNorm2d(in_planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=1,\n                               padding=1, bias=False)\n    def forward(self, x):\n        out = self.conv1(self.relu(self.bn1(x)))\n        return torch.cat([x, out], 1)\n\nclass _Up_Block(nn.Module):\n    def __init__(self, num_input_features):\n        super(_Up_Block, self).__init__()\n        self.add_module('layer1', _Layer1(num_input_features * 2))\n        self.add_module('layer2', _Layer2(num_input_features))\n\n    def forward(self, init_features):\n        out = self.layer1(init_features)\n        out = self.layer2(out)\n        return out\n\nclass Dense_Net(nn.Module):\n    def __init__(self, growth_rate=8):\n        super(Dense_Net, self).__init__()\n        \n        # 1st conv before any dense block\n        self.conv1 = nn.Conv2d(1, 4, kernel_size=3, stride=1, padding=1, bias=False)\n\n        # 1st block\n        self.block1 = _DenseBlock(4, 4, growth_rate)\n        in_planes = int(4+4*growth_rate)\n        self.trans1 = _Transition_Down(in_planes, in_planes*2)\n        # 2nd block\n        self.block2 = _DenseBlock(6, in_planes*2, growth_rate)\n        in_planes = int(in_planes*2+6*growth_rate)\n        self.trans2 = _Transition_Down(in_planes, in_planes*2)\n        # 3rd block\n        self.block3 = _DenseBlock(12, in_planes*2, growth_rate)\n        in_planes = int(in_planes*2+12*growth_rate)\n        self.trans3 = _Transition_Down(in_planes, in_planes*2)\n        # 4th block\n        self.block4 = _DenseBlock(8, in_planes*2, growth_rate)\n        in_planes = int(in_planes*2+8*growth_rate)\n        self.trans4 = _Transition_Down(in_planes, in_planes*2)\n\n        # conv layer at bottom of unet\n        self.conv2 = nn.Conv2d(in_planes*2, in_planes*2, kernel_size=1, stride=1)\n        self.trans5_up = _Transition_Up(in_planes*2, in_planes)\n\n        # 4th block\n        self.block4_up = _Up_Block(in_planes)\n        self.trans4_up = _Transition_Up(in_planes, 336)\n        # 3rd block\n        self.block3_up = _Up_Block(336)\n        self.trans3_up = _Transition_Up(336, 120)\n        # 2nd block\n        self.block2_up = _Up_Block(120)\n        self.trans2_up = _Transition_Up(120, 36)\n        # 1st block\n        self.block1_up = _Up_Block(36)\n\n        # last conv after all blocks\n        self.conv3 = nn.Conv2d(36, 1, kernel_size=1, stride=1)\n\n    def forward(self, x):\n        out = self.conv1(x)\n        out1 = self.block1(out) \n        out = self.trans1(out1)\n        out2 = self.block2(out) \n        out = self.trans2(out2)\n        out3 = self.block3(out) \n        out = self.trans3(out3)\n        out4 = self.block4(out) \n        out = self.trans4(out4) \n\n        out = self.trans5_up(self.conv2(out)) \n        out = torch.cat([out, out4], dim=1) \n        out = self.trans4_up(self.block4_up(out) ) \n        out = torch.cat([out, out3], dim=1) \n        out = self.trans3_up(self.block3_up(out))\n        out = torch.cat([out, out2], dim=1)\n        out = self.trans2_up(self.block2_up(out))\n        out = torch.cat([out, out1], dim=1)\n        out = self.conv3(self.block1_up(out))\n\n        out = torch.sigmoid(out)\n        return out","metadata":{"_uuid":"b368c438-722c-47fb-8659-28010133d3e3","_cell_guid":"19fd722b-d96b-4471-bb43-9df929e59d32","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}