{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"464c54d2-8e38-41b6-8ff4-b46e914bae9c","_uuid":"f5452a6b-ee72-4c58-8c30-ec9e24c017b5","collapsed":false,"execution":{"iopub.execute_input":"2024-05-07T23:27:09.148717Z","iopub.status.busy":"2024-05-07T23:27:09.148355Z","iopub.status.idle":"2024-05-07T23:27:14.144189Z","shell.execute_reply":"2024-05-07T23:27:14.143389Z","shell.execute_reply.started":"2024-05-07T23:27:09.148687Z"},"jupyter":{"outputs_hidden":false},"trusted":true},"outputs":[],"source":["import configparser\n","from pathlib import Path\n","\n","from matplotlib.backends.backend_pdf import PdfPages\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from scipy.spatial import distance\n","from sklearn.model_selection import train_test_split\n","import torch\n","from torch import optim, Tensor\n","from torch.nn import (\n","    functional as F,\n","    Module,\n","    utils\n",")\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","import gc"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T23:27:14.146345Z","iopub.status.busy":"2024-05-07T23:27:14.145928Z","iopub.status.idle":"2024-05-07T23:27:14.487684Z","shell.execute_reply":"2024-05-07T23:27:14.486889Z","shell.execute_reply.started":"2024-05-07T23:27:14.146318Z"},"trusted":true},"outputs":[],"source":["import sys\n","import os\n","\n","sys.path.append('/kaggle/input')\n","import model_dr_unet, model_dense_unet, model_unet"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T23:27:14.489194Z","iopub.status.busy":"2024-05-07T23:27:14.488834Z","iopub.status.idle":"2024-05-07T23:27:14.496990Z","shell.execute_reply":"2024-05-07T23:27:14.496103Z","shell.execute_reply.started":"2024-05-07T23:27:14.489162Z"},"trusted":true},"outputs":[],"source":["class TqdmExtraFormat(tqdm):\n","    @property\n","    def format_dict(self):\n","        d = super(TqdmExtraFormat, self).format_dict\n","        total_time = d[\"elapsed\"] * (d[\"total\"] or 0) / max(d[\"n\"], 1)\n","        d.update(total_time=self.format_interval(total_time))\n","        return d"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T23:27:14.499441Z","iopub.status.busy":"2024-05-07T23:27:14.499179Z","iopub.status.idle":"2024-05-07T23:27:14.508797Z","shell.execute_reply":"2024-05-07T23:27:14.507945Z","shell.execute_reply.started":"2024-05-07T23:27:14.499419Z"},"trusted":true},"outputs":[],"source":["def plot(img, mask_true, mask_pred, idx):\n","    img = np.squeeze(img, axis=1)\n","    mask_true = np.squeeze(mask_true, axis=1)\n","    mask_pred = np.squeeze(mask_pred, axis=1)\n","    max_value = img.max()\n","    img /= max_value\n","\n","    num_slice = img.shape[0]\n","    fig, axs = plt.subplots(num_slice, 3)\n","    axs: list[list[plt.Axes]]\n","    for i in range(num_slice):\n","        axs[i][0].imshow(img[i], cmap='gray')\n","        axs[i][0].set_title(f'z = {i}')\n","        axs[i][1].imshow(mask_true[i], cmap='gray')\n","        axs[i][1].set_title(f'ID {idx:03d}\\nGround truth')\n","        axs[i][2].imshow(mask_pred[i], cmap='gray')\n","        axs[i][2].set_title('AI generated')\n","    for i in range(num_slice):\n","        for j in range(3):\n","            axs[i][j].tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)\n","    return fig"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T23:27:14.510603Z","iopub.status.busy":"2024-05-07T23:27:14.510319Z","iopub.status.idle":"2024-05-07T23:27:14.531409Z","shell.execute_reply":"2024-05-07T23:27:14.530664Z","shell.execute_reply.started":"2024-05-07T23:27:14.510568Z"},"trusted":true},"outputs":[],"source":["from pathlib import Path\n","\n","import nibabel as nib\n","import numpy as np\n","\n","class SliceDataset:\n","    def __init__(self, img_pathes: Path, mask_pathes: Path, intensity_min, intensity_max) -> None:\n","        self.img_pathes = img_pathes\n","        self.mask_pathes = mask_pathes\n","        self.slices = [nib.load(p).shape[-1] for p in self.img_pathes]\n","        self.cum_slices = np.cumsum(self.slices)\n","        self.intensity_min = intensity_min\n","        self.intensity_max = intensity_max\n","\n","    def __getitem__(self, index: int):\n","        path_index = np.searchsorted(self.cum_slices, index, side='right')\n","        if path_index == 0:\n","            slice_index = index\n","        else:\n","            slice_index = index - self.cum_slices[path_index - 1]\n","        \n","        mask = np.load(self.mask_pathes[path_index])[:,:,slice_index]\n","        mask = mask[::2, ::2]\n","        assert mask.shape == (256, 256), \"Resized image shape does not match desired shape\"\n","        mask = mask[np.newaxis, ...]\n","        \n","        img = nib.load(self.img_pathes[path_index]).get_fdata()[:,:,slice_index]\n","        img = img[::2, ::2]\n","        assert img.shape == (256, 256), \"Resized image shape does not match desired shape\"\n","        img = windowing(img, self.intensity_min, self.intensity_max)[np.newaxis, ...]\n","        \n","        return img.astype(np.float32), mask.astype(np.float32)\n","    \n","    def filter_samples(self, index):\n","        # Check if the sum of the mask for the given index is greater than 0\n","        path_index = np.searchsorted(self.cum_slices, index, side='right')\n","        if path_index == 0:\n","            slice_index = index\n","        else:\n","            slice_index = index - self.cum_slices[path_index - 1]\n","\n","        mask = np.load(self.mask_pathes[path_index])[:,:,slice_index]\n","        return np.sum(mask) > 0 # returns true if mask has values\n","    \n","    def __len__(self):\n","        return self.cum_slices[-1]\n","\n","def windowing(image, min_value, max_value):\n","    image_new = np.clip(image, min_value, max_value)\n","    image_new = (image_new - min_value) / (max_value - min_value)\n","    return image_new\n","\n","class Subset(SliceDataset):\n","    def __init__(self, dataset, indices):\n","        self.dataset = dataset\n","        self.indices = indices\n","\n","    def __len__(self):\n","        return len(self.indices)\n","\n","    def __getitem__(self, idx):\n","        return self.dataset[self.indices[idx]]"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T23:27:14.533343Z","iopub.status.busy":"2024-05-07T23:27:14.532780Z","iopub.status.idle":"2024-05-07T23:27:14.549281Z","shell.execute_reply":"2024-05-07T23:27:14.548375Z","shell.execute_reply.started":"2024-05-07T23:27:14.533312Z"},"trusted":true},"outputs":[],"source":["def train(config: configparser.ConfigParser):\n","    print('Training...')\n","\n","    img_train_val = Path('/kaggle/input/sarahliu-deeplearning/Full_Data/img_train_val')\n","    mask_train_val_pathes = sorted(Path('/kaggle/input/sarahliu-deeplearning/Full_Data/mask_train_val').glob('*.npy'))\n","    img_train_val_pathes = [img_train_val / p.name.replace('.npy', '.nii') for p in mask_train_val_pathes]\n","        \n","    print(f'len(img_train_val_pathes) = {len(img_train_val_pathes)}')\n","    print(f'len(mask_train_val_pathes) = {len(mask_train_val_pathes)}')\n","\n","    train_size = config['train'].getfloat('train_size')\n","    random_seed = config['train'].getint('random_seed')\n","\n","    img_train_pathes, img_val_pathes, mask_train_pathes, mask_val_pathes = train_test_split(\n","        img_train_val_pathes, mask_train_val_pathes, train_size=0.9, random_state=random_seed\n","    )\n","\n","    print(f'len(img_train_pathes) = {len(img_train_pathes)}')\n","    print(f'len(img_val_pathes) = {len(img_val_pathes)}')\n","    print(f'len(mask_train_pathes) = {len(mask_train_pathes)}')\n","    print(f'len(mask_val_pathes) = {len(mask_val_pathes)}')\n","\n","    intensity_min = config['train'].getint('intensity_min')\n","    intensity_max = config['train'].getint('intensity_max')\n","    trainset = SliceDataset(img_train_pathes, mask_train_pathes, intensity_min, intensity_max)\n","    valset = SliceDataset(img_val_pathes, mask_val_pathes, intensity_min, intensity_max)\n","    print(f'len(trainset) = {len(trainset)}')\n","    print(f'len(valset) = {len(valset)}')\n","    \n","    train_indices = [idx for idx in range(len(trainset)) if trainset.filter_samples(idx)]\n","    filtered_trainset = Subset(trainset, train_indices)\n","    val_indices = [idx for idx in range(len(valset)) if valset.filter_samples(idx)]\n","    filtered_valset = Subset(valset, val_indices)\n","    print(f'len(filtered_trainset) = {len(filtered_trainset)}')\n","    print(f'len(filtered_valset) = {len(filtered_valset)}')\n","\n","    trainloader = DataLoader(filtered_trainset, batch_size=8, shuffle=True, num_workers=1)\n","    valloader = DataLoader(filtered_valset, batch_size=8, shuffle=True, num_workers=1)\n","\n","    print(f'len(trainloader) = {len(trainloader)}')\n","    print(f'len(valloader) = {len(valloader)}')\n","\n","    #model_class = getattr(model_dr_unet, \"DRUNet\")\n","    model_class = getattr(model_unet, \"U_Net\")\n","    #model_class = getattr(model_dense_unet, \"Dense_Net\")\n","    model = model_class()\n","    \n","    print(f'model.__class__.__name__ = {model.__class__.__name__}')\n","    print()\n","\n","    device = config['train']['device']\n","    model.to(device)\n","    debug = False\n","\n","    optimizer = optim.Adam(model.parameters())\n","    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=1 / 10 ** .5, patience=2, verbose=True)\n","    \n","    val_metrics = Path(\"/kaggle/working/val_metrics.txt\")\n","    if val_metrics.is_file():\n","        val_metrics.unlink() \n","    \n","    for epoch in range(1, 8): \n","        if Path(\"/kaggle/working/temp_model_weights.pth\").is_file(): \n","            model.load_state_dict(torch.load(\"/kaggle/working/temp_model_weights.pth\"))\n","        print(f'epoch = {epoch:03d}')\n","\n","        train_epoch(config, trainloader, model, optimizer)\n","        torch.cuda.empty_cache()\n","\n","        val_epoch(config, valloader, model, scheduler)\n","        torch.cuda.empty_cache()\n","        print()\n","\n","        if debug and epoch == 2:\n","            break\n","        if optimizer.param_groups[0]['lr'] < 1e-6:\n","            break"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T23:27:14.550876Z","iopub.status.busy":"2024-05-07T23:27:14.550554Z","iopub.status.idle":"2024-05-07T23:27:14.562390Z","shell.execute_reply":"2024-05-07T23:27:14.561561Z","shell.execute_reply.started":"2024-05-07T23:27:14.550853Z"},"trusted":true},"outputs":[],"source":["def val_epoch(config: configparser.ConfigParser, loader: DataLoader, model: Module, scheduler: optim.lr_scheduler.ReduceLROnPlateau):\n","    print(f'length of validation loader = {len(loader)}')\n","    model.eval()\n","    device = config['train']['device']\n","    debug = False # config['train'].getboolean('debug')\n","    weights_save_path = Path(\"/kaggle/working/model_weights.pth\") # weights_save_path = Path(config['train']['save_path'])\n","    val_metrics_path = Path(\"/kaggle/working/val_metrics.txt\")\n","    new_metrics = []\n","    pdf = PdfPages('val_figures.pdf')\n","    \n","    if not val_metrics_path.is_file():\n","        old_metrics = [0]\n","    else:\n","        old_metrics = np.loadtxt(val_metrics_path)\n","    \n","    with tqdm(total=len(loader)) as pbar:\n","        for idx, sample in enumerate(loader):\n","            sample: tuple[Tensor, ...]\n","            img, mask_true = sample\n","            \n","            model_output = model(img.to(device))\n","            mask_pred = model_output.cpu().detach().numpy()\n","            mask_true = (mask_true == 1).numpy()\n","            dice = 1 - distance.dice(mask_pred.reshape(-1), mask_true.reshape(-1))\n","            new_metrics.append(dice)\n","            pbar.update()\n","\n","            fig = plot(img.numpy(), mask_true, mask_pred, idx)\n","            fig.set_size_inches(15, 5 * mask_true.shape[0])\n","            pdf.savefig(fig, bbox_inches='tight')\n","            plt.close()\n","\n","            if debug and idx == 1:\n","                break\n","\n","    pbar.close()\n","    pdf.close()\n","    \n","    print(f'dice = {np.mean(new_metrics)} ± {np.std(new_metrics)}')\n","    \n","    if np.mean(new_metrics) > np.mean(old_metrics) or not weights_save_path.is_file():\n","        print(\"Performance improved, saving new weights.\")\n","        torch.save(model.state_dict(), Path(\"/kaggle/working/model_weights.pth\"))\n","        \n","    scheduler.step(np.mean(new_metrics))\n","    np.savetxt(val_metrics_path, new_metrics, fmt='%.5f')"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T23:27:14.563816Z","iopub.status.busy":"2024-05-07T23:27:14.563513Z","iopub.status.idle":"2024-05-07T23:27:14.578296Z","shell.execute_reply":"2024-05-07T23:27:14.577534Z","shell.execute_reply.started":"2024-05-07T23:27:14.563772Z"},"trusted":true},"outputs":[],"source":["def test(config: configparser.ConfigParser):\n","    print('Testing...')\n","    \n","    img_train_val_test = Path(\"/kaggle/input/sarahliu-deeplearning/Full_Data/img_test\")\n","    mask_test_pathes = sorted(Path(\"/kaggle/input/sarahliu-deeplearning/Full_Data/mask_test\").glob('*.npy'))\n","    img_test_pathes = [img_train_val_test / p.name.replace('.npy', '.nii') for p in mask_test_pathes]\n","    weights_path = \"/kaggle/working/model_weights.pth\"\n","\n","    print(f'len(img_test_pathes) = {len(img_test_pathes)}')\n","    print(f'len(mask_test_pathes) = {len(mask_test_pathes)}')\n","\n","    intensity_min = config['train'].getint('intensity_min')\n","    intensity_max = config['train'].getint('intensity_max')\n","\n","    testset = SliceDataset(img_test_pathes, mask_test_pathes, intensity_min, intensity_max)\n","    print(f'len(testset) = {len(testset)}')\n","    \n","    test_indices = [idx for idx in range(len(testset)) if testset.filter_samples(idx)]\n","    filtered_testset = Subset(testset, test_indices)\n","    print(f'len(filtered_testset) = {len(filtered_testset)}')\n","\n","    testloader = DataLoader(filtered_testset, batch_size=8, shuffle=False, num_workers=1)\n","    print(f'len(testloader) = {len(testloader)}')\n","        \n","    #model_class = getattr(model_dr_unet, \"DRUNet\")\n","    model_class = getattr(model_unet, \"U_Net\")\n","    #model_class = getattr(model_dense_unet, \"Dense_Net\")\n","    model = model_class()\n","    \n","    print(f'model.__class__.__name__ = {model.__class__.__name__}')\n","    print()\n","    \n","    model.load_state_dict(torch.load(weights_path))\n","    device = config['train']['device']\n","    model.to(device)\n","    debug = False \n","    \n","    test_metrics_path = Path(config['test']['test_metrics'])\n","    new_metrics = []\n","    pdf = PdfPages('figures.pdf')\n","    \n","    if not test_metrics_path.is_file():\n","        old_metrics = [0]\n","    else:\n","        old_metrics = np.loadtxt(test_metrics_path)\n","\n","    with torch.no_grad(), tqdm(total=len(testloader)) as pbar:\n","        for idx, sample in enumerate(testloader):\n","            sample: tuple[Tensor, ...]\n","            img, mask_true = sample\n","            \n","            model_output = model(img.to(device))\n","            mask_pred = model_output.detach().cpu().numpy()\n","            mask_true = (mask_true == 1).numpy()\n","            dice = 1 - distance.dice(mask_pred.reshape(-1), mask_true.reshape(-1))\n","            new_metrics.append(dice)\n","            pbar.update()\n","            \n","            fig = plot(img.numpy(), mask_true, mask_pred, idx)\n","            fig.set_size_inches(15, 5 * mask_true.shape[0])\n","            pdf.savefig(fig, bbox_inches='tight')\n","            plt.close()\n","            \n","            if debug and idx == 1:\n","                break\n","    pbar.close()\n","    pdf.close()\n","    print(new_metrics)\n","    np.savetxt(test_metrics_path, new_metrics, fmt='%.5f')"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T23:27:14.579841Z","iopub.status.busy":"2024-05-07T23:27:14.579526Z","iopub.status.idle":"2024-05-07T23:27:15.681450Z","shell.execute_reply":"2024-05-07T23:27:15.680525Z","shell.execute_reply.started":"2024-05-07T23:27:14.579811Z"},"trusted":true},"outputs":[{"data":{"text/plain":["0"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["!rm -rf /kaggle/working/*\n","gc.collect()"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T23:27:15.685129Z","iopub.status.busy":"2024-05-07T23:27:15.684849Z","iopub.status.idle":"2024-05-07T23:27:15.695482Z","shell.execute_reply":"2024-05-07T23:27:15.694464Z","shell.execute_reply.started":"2024-05-07T23:27:15.685106Z"},"trusted":true},"outputs":[],"source":["def train_epoch(config: configparser.ConfigParser, loader: DataLoader, model: Module, optimizer: optim.Adam):\n","    print(f'length of train loader = {len(loader)}')\n","    model.train()\n","    device = config['train']['device']\n","    debug = False \n","\n","    loss_values = list()\n","    \n","    with tqdm(total=len(loader)) as pbar:\n","        for batch_idx, sample in enumerate(loader):\n","            sample: tuple[Tensor, ...]\n","            img, mask_true = sample\n","            model_output = model(img.to(device)) \n","             \n","            mask_pred = model_output.float().to(device).requires_grad_()\n","            mask_true = (mask_true == 1).float().to(device).requires_grad_()\n","\n","            intersection = torch.sum(mask_pred * mask_true)\n","            union = torch.sum(mask_pred) + torch.sum(mask_true)\n","            dice = (2. * intersection + 1e-6) / (union + 1e-6)\n","            loss = 1. - dice\n","            \n","            optimizer.zero_grad()\n","            loss.backward()\n","            loss_values.append(loss.item())\n","            optimizer.step()\n","            \n","            pbar.update()\n","            if debug and batch_idx == 1:\n","                    break\n","                    \n","    torch.save(model.state_dict(), Path(\"/kaggle/working/temp_model_weights.pth\"))\n","    \n","    pbar.close()\n","    print(f'loss = {np.mean(loss_values)} ± {np.std(loss_values)}')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-07T23:27:15.696748Z","iopub.status.busy":"2024-05-07T23:27:15.696421Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training...\n","len(img_train_val_pathes) = 287\n","len(mask_train_val_pathes) = 287\n","len(img_train_pathes) = 258\n","len(img_val_pathes) = 29\n","len(mask_train_pathes) = 258\n","len(mask_val_pathes) = 29\n","len(trainset) = 8266\n","len(valset) = 923\n","len(filtered_trainset) = 2148\n","len(filtered_valset) = 197\n","len(trainloader) = 269\n","len(valloader) = 25\n","model.__class__.__name__ = U_Net\n","\n","epoch = 001\n","length of train loader = 269\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 269/269 [03:15<00:00,  1.38it/s]\n"]},{"name":"stdout","output_type":"stream","text":["loss = 0.4046789166209423 ± 0.2564838437991685\n","length of validation loader = 25\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 25/25 [01:56<00:00,  4.64s/it]\n"]},{"name":"stdout","output_type":"stream","text":["dice = 0.6902853331030738 ± 0.1016419319906613\n","Performance improved, saving new weights.\n","\n","epoch = 002\n","length of train loader = 269\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 269/269 [02:30<00:00,  1.79it/s]\n"]},{"name":"stdout","output_type":"stream","text":["loss = 0.20222872850177012 ± 0.09381241758798027\n","length of validation loader = 25\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 25/25 [01:51<00:00,  4.46s/it]\n"]},{"name":"stdout","output_type":"stream","text":["dice = 0.7404911279514405 ± 0.15741061612971627\n","Performance improved, saving new weights.\n","\n","epoch = 003\n","length of train loader = 269\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 269/269 [02:30<00:00,  1.79it/s]\n"]},{"name":"stdout","output_type":"stream","text":["loss = 0.1879809966317783 ± 0.09551823410838048\n","length of validation loader = 25\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 25/25 [01:55<00:00,  4.61s/it]\n"]},{"name":"stdout","output_type":"stream","text":["dice = 0.7457879616353579 ± 0.15172477796068734\n","Performance improved, saving new weights.\n","\n","epoch = 004\n","length of train loader = 269\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 269/269 [02:30<00:00,  1.79it/s]\n"]},{"name":"stdout","output_type":"stream","text":["loss = 0.1784350876471367 ± 0.09065120804486151\n","length of validation loader = 25\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 25/25 [01:55<00:00,  4.64s/it]\n"]},{"name":"stdout","output_type":"stream","text":["dice = 0.7697837863805664 ± 0.11152807402764905\n","Performance improved, saving new weights.\n","\n","epoch = 005\n","length of train loader = 269\n"]},{"name":"stderr","output_type":"stream","text":[" 63%|██████▎   | 170/269 [01:35<00:55,  1.80it/s]"]}],"source":["config = configparser.ConfigParser()\n","config.read('/kaggle/input/sarahliu-deeplearning/config.ini')\n","train(config)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test(config)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4855186,"sourceId":8339770,"sourceType":"datasetVersion"},{"sourceId":173565996,"sourceType":"kernelVersion"},{"sourceId":176165757,"sourceType":"kernelVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
